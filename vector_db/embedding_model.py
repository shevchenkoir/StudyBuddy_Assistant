
# # # # import os
# # # # from dotenv import load_dotenv
# # # # # from langchain_community.embeddings import OllamaEmbeddings
# # # # from langchain_ollama import OllamaEmbeddings
# # # # from typing import List

# # # # load_dotenv()

# # # # # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏
# # # # OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.1:latest")
# # # # # OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "nomic-embed-text")
# # # # OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

# # # # # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
# # # # try:
# # # #     embedding_model = OllamaEmbeddings(
# # # #         model=OLLAMA_MODEL,
# # # #         base_url=OLLAMA_BASE_URL,
# # # #         temperature=0.1
# # # #     )
    
# # # # except Exception as e:
# # # #     print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Ollama: {e}")
# # # #     embedding_model = None

# # # # def get_text_embedding(text: str) -> List[float]:
# # # #     """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –º–æ–¥–µ–ª–∏"""
# # # #     if not embedding_model:
# # # #         print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
# # # #         return []
    
# # # #     try:
# # # #         return embedding_model.embed_query(text)
# # # #     except Exception as e:
# # # #         print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
# # # #         print(f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ–¥–µ–ª—å: ollama run {OLLAMA_MODEL}")
# # # #         return []




# # # import os
# # # from dotenv import load_dotenv
# # # from langchain_ollama import OllamaEmbeddings
# # # from typing import List

# # # load_dotenv()

# # # OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "nomic-embed-text")
# # # OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

# # # try:
# # #     embedding_model = OllamaEmbeddings(
# # #         model=OLLAMA_MODEL,
# # #         base_url=OLLAMA_BASE_URL,
# # #         temperature=0.1
# # #     )
# # #     print(f"‚úÖ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {OLLAMA_MODEL}")
# # # except Exception as e:
# # #     print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Ollama: {e}")
# # #     embedding_model = None

# # # def get_text_embedding(text: str) -> List[float]:
# # #     if not embedding_model:
# # #         print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
# # #         return []
    
# # #     try:
# # #         print(f"üìå –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç: {text[:30]}...")
# # #         vector = embedding_model.embed_query(text)
# # #         print(f"üìå –≠–º–±–µ–¥–¥–∏–Ω–≥ (–¥–ª–∏–Ω–∞): {len(vector)}")
# # #         return vector
# # #     except Exception as e:
# # #         print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
# # #         print(f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ–¥–µ–ª—å: ollama run {OLLAMA_MODEL}")
# # #         return []

# # # from sentence_transformers import SentenceTransformer
# # # from typing import List

# # # model = SentenceTransformer('all-MiniLM-L6-v2')

# # # def get_text_embedding(text: str) -> List[float]:
# # #     try:
# # #         print(f"üìå –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç: {text[:30]}...")
# # #         vector = model.encode(text).tolist()
# # #         print(f"üìå –≠–º–±–µ–¥–¥–∏–Ω–≥ (–¥–ª–∏–Ω–∞): {len(vector)}")
# # #         return vector
# # #     except Exception as e:
# # #         print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
# # #         return []



# # import os
# # from dotenv import load_dotenv
# # from typing import List
# # from langchain_ollama import OllamaEmbeddings

# # load_dotenv()

# # # –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
# # OLLAMA_EMBED_MODEL = os.getenv("OLLAMA_EMBED_MODEL", "nomic-embed-text")
# # OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

# # try:
# #     embedding_model = OllamaEmbeddings(
# #         model=OLLAMA_EMBED_MODEL,
# #         base_url=OLLAMA_BASE_URL
# #     )
# #     print(f"‚úÖ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {OLLAMA_EMBED_MODEL}")
# # except Exception as e:
# #     print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Ollama Embeddings: {e}")
# #     embedding_model = None

# # def get_text_embedding(text: str) -> List[float]:
# #     """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –º–æ–¥–µ–ª–∏"""
# #     if not embedding_model:
# #         print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
# #         return []
# #     try:
# #         return embedding_model.embed_query(text)
# #     except Exception as e:
# #         print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
# #         print(f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ–¥–µ–ª—å: ollama run {OLLAMA_EMBED_MODEL}")
# #         return []



# # vector_db/embedding_model.py
# import os
# from typing import List
# from functools import lru_cache

# from dotenv import load_dotenv
# load_dotenv()

# # –ú–æ–∂–Ω–æ –ø–æ–¥–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ .env, –¥–µ—Ñ–æ–ª—Ç ‚Äî –ª—ë–≥–∫–∞—è –∏ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è
# EMBEDDING_MODEL_ID = os.getenv("EMBEDDING_MODEL_ID", "sentence-transformers/all-MiniLM-L6-v2")

# @lru_cache(maxsize=1)
# def _load_model():
#     """
#     –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å.
#     –ù–µ —Ç—Ä–µ–±—É–µ—Ç Ollama. –†–∞–±–æ—Ç–∞–µ—Ç –æ—Ñ–ª–∞–π–Ω.
#     """
#     from sentence_transformers import SentenceTransformer
#     # –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–æ –∫–æ—Ä–æ—Ç–∫–æ–º—É id —Ç–æ–∂–µ (–∏ –ø–æ–ª–Ω—ã–π, –∏ –∫–æ—Ä–æ—Ç–∫–∏–π —Ä–∞–±–æ—Ç–∞—é—Ç)
#     model_name = EMBEDDING_MODEL_ID.split("/")[-1]
#     try:
#         model = SentenceTransformer(EMBEDDING_MODEL_ID)
#     except Exception:
#         # fallback –Ω–∞ –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è, –µ—Å–ª–∏ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
#         model = SentenceTransformer(model_name)
#     return model

# def get_text_embedding(text: str) -> List[float]:
#     """
#     –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –∫–∞–∫ —Å–ø–∏—Å–æ–∫ float.
#     –ü—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ (—á—Ç–æ–±—ã –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –º–æ–≥ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –Ω–µ—É–¥–∞—á–Ω—ã–µ —á–∞–Ω–∫–∏).
#     """
#     text = (text or "").strip()
#     if not text:
#         return []
#     try:
#         model = _load_model()
#         vec = model.encode(text, normalize_embeddings=True)  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ‚Äî –ø–æ–ª–µ–∑–Ω–∞ –¥–ª—è L2
#         return vec.astype("float32").tolist()
#     except Exception as e:
#         print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (sentence-transformers): {e}")



import os
from dotenv import load_dotenv
from langchain_ollama import OllamaEmbeddings
from typing import List

load_dotenv()

# –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ‚Äî –ª—ë–≥–∫–∞—è
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL_EMBED", "nomic-embed-text")
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

try:
    embedding_model = OllamaEmbeddings(
        model=OLLAMA_MODEL,
        base_url=OLLAMA_BASE_URL
    )
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Ollama: {e}")
    embedding_model = None

def get_text_embedding(text: str) -> List[float]:
    if not embedding_model:
        print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        return []
    try:
        return embedding_model.embed_query(text)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
        print(f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ–¥–µ–ª—å: ollama run {OLLAMA_MODEL}")
        return []
