

# # # import sys, os
# # # sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))


# # # import streamlit as st
# # # from core.rag_engine import get_answer
# # # from data_ingestion.pdf_loader import extract_text_from_pdf
# # # from data_ingestion.docx_loader import extract_text_from_docx
# # # from data_ingestion.preprocessor import clean_text
# # # from data_ingestion.splitter import split_text
# # # from vector_db.embedding_model import documents
# # # from vector_db.faiss_interface import initialize_index


# # # UPLOAD_DIR = "uploaded_materials"

# # # def run_app():
# # #     st.set_page_config(page_title="StudyBuddy", layout="wide")
# # #     st.title("üìò StudyBuddy: –¢–≤–æ–π –ò–ò-—Ç—å—é—Ç–æ—Ä")

# # #     # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
# # #     if "chat_history" not in st.session_state:
# # #         st.session_state.chat_history = []

# # #     # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞
# # #     uploaded_file = st.file_uploader("üìö –ó–∞–≥—Ä—É–∑–∏—Ç–µ —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª (PDF –∏–ª–∏ DOCX)", type=["pdf", "docx"])
# # #     if uploaded_file:
# # #         os.makedirs(UPLOAD_DIR, exist_ok=True)
# # #         file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
# # #         with open(file_path, "wb") as f:
# # #             f.write(uploaded_file.getbuffer())
# # #         st.success(f"–§–∞–π–ª '{uploaded_file.name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")

# # #         # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
# # #         if uploaded_file.name.endswith(".pdf"):
# # #             raw_text = extract_text_from_pdf(file_path)
# # #         else:
# # #             raw_text = extract_text_from_docx(file_path)

# # #         cleaned = clean_text(raw_text)
# # #         chunks = split_text(cleaned)
# # #         documents.clear()
# # #         documents.extend(chunks)
# # #         initialize_index()
# # #         st.success("–ú–∞—Ç–µ—Ä–∏–∞–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")

# # #     # –í–≤–æ–¥ –≤–æ–ø—Ä–æ—Å–∞
# # #     st.subheader("üí¨ –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")
# # #     question = st.text_input("–í–∞—à –≤–æ–ø—Ä–æ—Å:")

# # #     if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å") and question:
# # #         st.session_state.chat_history.append({"role": "user", "content": question})
# # #         answer = get_answer(question, st.session_state.chat_history)
# # #         st.session_state.chat_history.append({"role": "assistant", "content": answer})
# # #         st.markdown(f"**–û—Ç–≤–µ—Ç:** {answer}")

# # #     # –ò—Å—Ç–æ—Ä–∏—è
# # #     if st.session_state.chat_history:
# # #         with st.expander("üìú –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞"):
# # #             for entry in st.session_state.chat_history:
# # #                 role = "üßë" if entry["role"] == "user" else "ü§ñ"
# # #                 st.markdown(f"{role} **{entry['role']}**: {entry['content']}")

# # # # –ó–∞–ø—É—Å–∫
# # # if __name__ == "__main__":
# # #     run_app()

# # # from pathlib import Path
# # # import sys, os
# # # sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# # # import streamlit as st
# # # from core.rag_engine import get_answer
# # # from core.pedagogy import should_hint, generate_hint
# # # from gui.session_manager import get_session_history
# # # from llm.quiz_generator import generate_quiz
# # # from ethics.user_feedback import save_feedback

# # # from data_ingestion.pdf_loader import extract_text_from_pdf
# # # from data_ingestion.docx_loader import extract_text_from_docx
# # # from data_ingestion.splitter import split_text
# # # from data_ingestion.preprocessor import clean_text
# # # from vector_db.embedding_model import documents
# # # from vector_db.faiss_interface import initialize_index

# # # from vector_db.embedding_model import documents, create_embeddings
# # # from vector_db.faiss_interface import initialize_index

# # # UPLOAD_DIR = "uploaded_materials"

# # # def handle_file_upload():
# # #     st.subheader("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ–±–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞")
# # #     uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ PDF –∏–ª–∏ DOCX —Ñ–∞–π–ª", type=["pdf", "docx"])
# # #     if uploaded_file:
# # #         os.makedirs(UPLOAD_DIR, exist_ok=True)
# # #         file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
# # #         with open(file_path, "wb") as f:
# # #             f.write(uploaded_file.getbuffer())
# # #         st.success(f"–§–∞–π–ª '{uploaded_file.name}' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

# # #         try:
# # #             # üìñ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
# # #             if uploaded_file.name.endswith(".pdf"):
# # #                 raw_text = extract_text_from_pdf(file_path)
# # #             else:
# # #                 raw_text = extract_text_from_docx(file_path)

# # #             # üßπ –û—á–∏—Å—Ç–∫–∞ –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ
# # #             cleaned = clean_text(raw_text)
# # #             chunks = split_text(cleaned)
# # #             documents.clear()
# # #             documents.extend(chunks)

# # #             # üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ + –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞
# # #             create_embeddings(documents)
# # #             initialize_index()

# # #             st.success("–ú–∞—Ç–µ—Ä–∏–∞–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
# # #         except Exception as e:
# # #             st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")


# # # def run_app():
# # #     st.set_page_config(page_title="StudyBuddy", layout="wide")
# # #     st.title("üìò StudyBuddy: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫")

# # #     handle_file_upload()

# # #     history = get_session_history()
# # #     tab1, tab2 = st.tabs(["üí¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", "üìù Quiz"])

# # #     with tab1:
# # #         st.subheader("–î–∏–∞–ª–æ–≥ —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º")
# # #         question = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å:")
# # #         use_pedagogy = st.checkbox("–†–µ–∂–∏–º –ø–æ–¥—Å–∫–∞–∑–æ–∫ (–Ω–µ –¥–∞–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ)", value=True)

# # #         if st.button("–û—Ç–≤–µ—Ç–∏—Ç—å") and question:
# # #             if use_pedagogy and should_hint(question):
# # #                 answer = generate_hint(question)
# # #             else:
# # #                 answer = get_answer(question, st.session_state.chat_history)

# # #             history.add_turn(question, answer)
# # #             st.markdown(f"**–û—Ç–≤–µ—Ç:** {answer}")

# # #             st.markdown("---")
# # #             st.markdown("–û—Ü–µ–Ω–∏—Ç–µ –æ—Ç–≤–µ—Ç:")
# # #             col1, col2 = st.columns(2)
# # #             with col1:
# # #                 if st.button("üëç –ü–æ–ª–µ–∑–Ω–æ"):
# # #                     save_feedback(question, answer, True)
# # #             with col2:
# # #                 if st.button("üëé –ù–µ –ø–æ–ª–µ–∑–Ω–æ"):
# # #                     save_feedback(question, answer, False)

# # #         st.markdown("### –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:")
# # #         for q, a in history.get_history():
# # #             st.markdown(f"**–í—ã:** {q}\\n\\n**–ë–æ—Ç:** {a}")

# # #     with tab2:
# # #         st.subheader("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ")
# # #         topic = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è —Ç–µ—Å—Ç–∞:")
# # #         num_q = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤", 1, 10, 5)

# # #         if st.button("–°–æ–∑–¥–∞—Ç—å Quiz"):
# # #             quiz = generate_quiz(topic, num_q)
# # #             st.text_area("–í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏", quiz, height=300)

# # # if __name__ == "__main__":
# # #     run_app()

# # # import sys, os
# # # sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
# # # from config import embedding_model, OLLAMA_MODEL

# # import sys, os
# # from pathlib import Path
# # sys.path.append(str(Path(__file__).parent.parent))
# # from config import embedding_model, OLLAMA_MODEL

# # # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞—ë–º –º–æ–¥–µ–ª—å Qwen
# # import os as _os

# # _os.environ.setdefault("OLLAMA_MODEL", "qwen2.5:1.5b-instruct")  # –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
# # _os.environ.setdefault("OLLAMA_EMBED_MODEL", "nomic-embed-text") # –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
# # _os.environ.setdefault("OLLAMA_BASE_URL", "http://localhost:11434")



# # import streamlit as st
# # from core.rag_engine import get_answer
# # from core.pedagogy import should_hint, generate_hint
# # from gui.session_manager import get_session_history
# # from llm.quiz_generator import generate_quiz
# # from ethics.user_feedback import save_feedback

# # from data_ingestion.pdf_loader import extract_text_from_pdf
# # from data_ingestion.docx_loader import extract_text_from_docx
# # from data_ingestion.splitter import split_text
# # from data_ingestion.preprocessor import clean_text
# # from vector_db.faiss_interface import initialize_index

# # UPLOAD_DIR = "uploaded_materials"




# # import sys, os
# # from pathlib import Path
# # sys.path.append(str(Path(__file__).parent.parent))
# # from config import OLLAMA_MODEL, embedding_model


# # import streamlit as st
# # from core.rag_engine import get_answer
# # from core.pedagogy import should_hint, generate_hint
# # from gui.session_manager import get_session_history
# # from llm.quiz_generator import generate_quiz
# # from ethics.user_feedback import save_feedback

# # from data_ingestion.pdf_loader import extract_text_from_pdf
# # from data_ingestion.docx_loader import extract_text_from_docx
# # from data_ingestion.splitter import split_text
# # from data_ingestion.preprocessor import clean_text
# # from vector_db.faiss_interface import initialize_index

# # UPLOAD_DIR = "uploaded_materials"

# # def handle_file_upload():
# #     st.subheader("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ–±–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞")
# #     uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ PDF –∏–ª–∏ DOCX —Ñ–∞–π–ª", type=["pdf", "docx"])
# #     if uploaded_file:
# #         os.makedirs(UPLOAD_DIR, exist_ok=True)
# #         file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
# #         with open(file_path, "wb") as f:
# #             f.write(uploaded_file.getbuffer())
# #         st.success(f"–§–∞–π–ª '{uploaded_file.name}' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

# #         try:
# #             st.write("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞...")
# #             if uploaded_file.name.endswith(".pdf"):
# #                 raw_text = extract_text_from_pdf(file_path)
# #             else:
# #                 raw_text = extract_text_from_docx(file_path)

# #             st.write(f"üìú –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(raw_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞.")

# #             cleaned = clean_text(raw_text)
# #             st.write(f"üßπ –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(cleaned)} —Å–∏–º–≤–æ–ª–æ–≤.")

# #             chunks = split_text(cleaned)
# #             st.write(f"üîπ –ß–∞–Ω–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(chunks)}")
# #             if chunks:
# #                 st.write(f"üß© –ü—Ä–∏–º–µ—Ä —á–∞–Ω–∫–∞:\n\n{chunks[0]}")

# #             st.write("üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞...")
# #             initialize_index(chunks)

# #             st.session_state["documents"] = chunks
# #             st.success("–ú–∞—Ç–µ—Ä–∏–∞–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
# #         except Exception as e:
# #             st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")

# # def run_app():
# #     st.set_page_config(page_title="StudyBuddy", layout="wide")
# #     st.title("üìò StudyBuddy: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫")

# #     handle_file_upload()

# #     history = get_session_history()
# #     tab1, tab2 = st.tabs(["üí¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", "üìù Quiz"])

# #     with tab1:
# #         st.subheader("–î–∏–∞–ª–æ–≥ —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º")
# #         question = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å:")
# #         use_pedagogy = st.checkbox("–†–µ–∂–∏–º –ø–æ–¥—Å–∫–∞–∑–æ–∫ (–Ω–µ –¥–∞–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ)", value=True)

# #         if st.button("–û—Ç–≤–µ—Ç–∏—Ç—å") and question:
# #             if "documents" not in st.session_state or not st.session_state["documents"]:
# #                 st.warning("‚ùó –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–π—Ç–µ —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª.")
# #             else:
# #                 if use_pedagogy and should_hint(question):
# #                     answer = generate_hint(question)
# #                 else:
# #                     answer = get_answer(question, st.session_state.chat_history)

# #                 history.add_turn(question, answer)
# #                 st.markdown(f"**–û—Ç–≤–µ—Ç:** {answer}")

# #                 st.markdown("---")
# #                 st.markdown("–û—Ü–µ–Ω–∏—Ç–µ –æ—Ç–≤–µ—Ç:")
# #                 col1, col2 = st.columns(2)
# #                 with col1:
# #                     if st.button("üëç –ü–æ–ª–µ–∑–Ω–æ"):
# #                         save_feedback(question, answer, True)
# #                 with col2:
# #                     if st.button("üëé –ù–µ –ø–æ–ª–µ–∑–Ω–æ"):
# #                         save_feedback(question, answer, False)

# #         st.markdown("### –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:")
# #         for q, a in history.get_history():
# #             st.markdown(f"**–í—ã:** {q}\n\n**–ë–æ—Ç:** {a}")

# #     with tab2:
# #         st.subheader("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ")
# #         topic = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è —Ç–µ—Å—Ç–∞:")
# #         num_q = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤", 1, 10, 5)

# #         if st.button("–°–æ–∑–¥–∞—Ç—å Quiz"):
# #             quiz = generate_quiz(topic, num_q)
# #             st.text_area("–í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏", quiz, height=300)

# # if __name__ == "__main__":
# #     run_app()
import sys, os
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from config import embedding_model, OLLAMA_MODEL
from output.speech_output import speak

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞—ë–º –º–æ–¥–µ–ª—å Qwen
import os as _os

_os.environ.setdefault("OLLAMA_MODEL", "qwen2.5:1.5b-instruct")  # –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
_os.environ.setdefault("OLLAMA_EMBED_MODEL", "nomic-embed-text") # –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
_os.environ.setdefault("OLLAMA_BASE_URL", "http://localhost:11434")

import streamlit as st
from core.rag_engine import get_answer
from core.pedagogy import should_hint, generate_hint
from gui.session_manager import get_session_history
from llm.quiz_generator import generate_quiz
from ethics.user_feedback import save_feedback

from data_ingestion.pdf_loader import extract_text_from_pdf
from data_ingestion.docx_loader import extract_text_from_docx
from data_ingestion.splitter import split_text
from data_ingestion.preprocessor import clean_text


UPLOAD_DIR = "uploaded_materials"




import sys, os
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from config import OLLAMA_MODEL, embedding_model


import streamlit as st
from core.rag_engine import get_answer
from core.pedagogy import should_hint, generate_hint
from gui.session_manager import get_session_history
from llm.quiz_generator import generate_quiz
from ethics.user_feedback import save_feedback

from data_ingestion.pdf_loader import extract_text_from_pdf
from data_ingestion.docx_loader import extract_text_from_docx
from data_ingestion.splitter import split_text
from data_ingestion.preprocessor import clean_text
from vector_db.faiss_interface import initialize_index

UPLOAD_DIR = "uploaded_materials"

def handle_file_upload():
    st.subheader("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ–±–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞")
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ PDF –∏–ª–∏ DOCX —Ñ–∞–π–ª", type=["pdf", "docx"])
    if uploaded_file:
        os.makedirs(UPLOAD_DIR, exist_ok=True)
        file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.success(f"–§–∞–π–ª '{uploaded_file.name}' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

        try:
            st.write("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞...")
            if uploaded_file.name.endswith(".pdf"):
                raw_text = extract_text_from_pdf(file_path)
            else:
                raw_text = extract_text_from_docx(file_path)

            st.write(f"üìú –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(raw_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞.")

            cleaned = clean_text(raw_text)
            st.write(f"üßπ –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(cleaned)} —Å–∏–º–≤–æ–ª–æ–≤.")

            chunks = split_text(cleaned)
            st.write(f"üîπ –ß–∞–Ω–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(chunks)}")
            if chunks:
                st.write(f"üß© –ü—Ä–∏–º–µ—Ä —á–∞–Ω–∫–∞:\n\n{chunks[0]}")

            st.write("üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞...")
            initialize_index(chunks)

            st.session_state["documents"] = chunks
            st.success("–ú–∞—Ç–µ—Ä–∏–∞–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")

def run_app():
    st.set_page_config(page_title="StudyBuddy", layout="wide")
    st.title("üìò StudyBuddy: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫")

    handle_file_upload()

    history = get_session_history()
    tab1, tab2 = st.tabs(["üí¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", "üìù Quiz"])

    with tab1:
        st.subheader("–î–∏–∞–ª–æ–≥ —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º")
        question = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å:")
        use_pedagogy = st.checkbox("–†–µ–∂–∏–º –ø–æ–¥—Å–∫–∞–∑–æ–∫ (–Ω–µ –¥–∞–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ)", value=True)

        if st.button("–û—Ç–≤–µ—Ç–∏—Ç—å") and question:
            if "documents" not in st.session_state or not st.session_state["documents"]:
                st.warning("‚ùó –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–π—Ç–µ —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª.")
            else:
                if use_pedagogy and should_hint(question):
                    answer = generate_hint(question)
                else:
                    answer = get_answer(question, st.session_state.chat_history)

                history.add_turn(question, answer)
                st.markdown(f"**–û—Ç–≤–µ—Ç:** {answer}")
                speak(answer)

                st.markdown("---")
                st.markdown("–û—Ü–µ–Ω–∏—Ç–µ –æ—Ç–≤–µ—Ç:")
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("üëç –ü–æ–ª–µ–∑–Ω–æ"):
                        save_feedback(question, answer, True)
                with col2:
                    if st.button("üëé –ù–µ –ø–æ–ª–µ–∑–Ω–æ"):
                        save_feedback(question, answer, False)

        st.markdown("### –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:")
        for q, a in history.get_history():
            st.markdown(f"**–í—ã:** {q}\n\n**–ë–æ—Ç:** {a}")

    with tab2:
        st.subheader("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ")
        topic = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è —Ç–µ—Å—Ç–∞:")
        num_q = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤", 1, 10, 5)

        if st.button("–°–æ–∑–¥–∞—Ç—å Quiz"):
            quiz = generate_quiz(topic, num_q)
            st.text_area("–í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏", quiz, height=300)

if __name__ == "__main__":
    run_app()

