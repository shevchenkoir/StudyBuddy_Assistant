

# # # # import sys, os
# # # # sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))


# # # # import streamlit as st
# # # # from core.rag_engine import get_answer
# # # # from data_ingestion.pdf_loader import extract_text_from_pdf
# # # # from data_ingestion.docx_loader import extract_text_from_docx
# # # # from data_ingestion.preprocessor import clean_text
# # # # from data_ingestion.splitter import split_text
# # # # from vector_db.embedding_model import documents
# # # # from vector_db.faiss_interface import initialize_index


# # # # UPLOAD_DIR = "uploaded_materials"

# # # # def run_app():
# # # #     st.set_page_config(page_title="StudyBuddy", layout="wide")
# # # #     st.title("üìò StudyBuddy: –¢–≤–æ–π –ò–ò-—Ç—å—é—Ç–æ—Ä")

# # # #     # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
# # # #     if "chat_history" not in st.session_state:
# # # #         st.session_state.chat_history = []

# # # #     # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞
# # # #     uploaded_file = st.file_uploader("üìö –ó–∞–≥—Ä—É–∑–∏—Ç–µ —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª (PDF –∏–ª–∏ DOCX)", type=["pdf", "docx"])
# # # #     if uploaded_file:
# # # #         os.makedirs(UPLOAD_DIR, exist_ok=True)
# # # #         file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
# # # #         with open(file_path, "wb") as f:
# # # #             f.write(uploaded_file.getbuffer())
# # # #         st.success(f"–§–∞–π–ª '{uploaded_file.name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")

# # # #         # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
# # # #         if uploaded_file.name.endswith(".pdf"):
# # # #             raw_text = extract_text_from_pdf(file_path)
# # # #         else:
# # # #             raw_text = extract_text_from_docx(file_path)

# # # #         cleaned = clean_text(raw_text)
# # # #         chunks = split_text(cleaned)
# # # #         documents.clear()
# # # #         documents.extend(chunks)
# # # #         initialize_index()
# # # #         st.success("–ú–∞—Ç–µ—Ä–∏–∞–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")

# # # #     # –í–≤–æ–¥ –≤–æ–ø—Ä–æ—Å–∞
# # # #     st.subheader("üí¨ –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")
# # # #     question = st.text_input("–í–∞—à –≤–æ–ø—Ä–æ—Å:")

# # # #     if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å") and question:
# # # #         st.session_state.chat_history.append({"role": "user", "content": question})
# # # #         answer = get_answer(question, st.session_state.chat_history)
# # # #         st.session_state.chat_history.append({"role": "assistant", "content": answer})
# # # #         st.markdown(f"**–û—Ç–≤–µ—Ç:** {answer}")

# # # #     # –ò—Å—Ç–æ—Ä–∏—è
# # # #     if st.session_state.chat_history:
# # # #         with st.expander("üìú –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞"):
# # # #             for entry in st.session_state.chat_history:
# # # #                 role = "üßë" if entry["role"] == "user" else "ü§ñ"
# # # #                 st.markdown(f"{role} **{entry['role']}**: {entry['content']}")

# # # # # –ó–∞–ø—É—Å–∫
# # # # if __name__ == "__main__":
# # # #     run_app()

# # # # from pathlib import Path
# # # # import sys, os
# # # # sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# # # # import streamlit as st
# # # # from core.rag_engine import get_answer
# # # # from core.pedagogy import should_hint, generate_hint
# # # # from gui.session_manager import get_session_history
# # # # from llm.quiz_generator import generate_quiz
# # # # from ethics.user_feedback import save_feedback

# # # # from data_ingestion.pdf_loader import extract_text_from_pdf
# # # # from data_ingestion.docx_loader import extract_text_from_docx
# # # # from data_ingestion.splitter import split_text
# # # # from data_ingestion.preprocessor import clean_text
# # # # from vector_db.embedding_model import documents
# # # # from vector_db.faiss_interface import initialize_index

# # # # from vector_db.embedding_model import documents, create_embeddings
# # # # from vector_db.faiss_interface import initialize_index

# # # # UPLOAD_DIR = "uploaded_materials"

# # # # def handle_file_upload():
# # # #     st.subheader("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ–±–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞")
# # # #     uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ PDF –∏–ª–∏ DOCX —Ñ–∞–π–ª", type=["pdf", "docx"])
# # # #     if uploaded_file:
# # # #         os.makedirs(UPLOAD_DIR, exist_ok=True)
# # # #         file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
# # # #         with open(file_path, "wb") as f:
# # # #             f.write(uploaded_file.getbuffer())
# # # #         st.success(f"–§–∞–π–ª '{uploaded_file.name}' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

# # # #         try:
# # # #             # üìñ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
# # # #             if uploaded_file.name.endswith(".pdf"):
# # # #                 raw_text = extract_text_from_pdf(file_path)
# # # #             else:
# # # #                 raw_text = extract_text_from_docx(file_path)

# # # #             # üßπ –û—á–∏—Å—Ç–∫–∞ –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ
# # # #             cleaned = clean_text(raw_text)
# # # #             chunks = split_text(cleaned)
# # # #             documents.clear()
# # # #             documents.extend(chunks)

# # # #             # üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ + –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞
# # # #             create_embeddings(documents)
# # # #             initialize_index()

# # # #             st.success("–ú–∞—Ç–µ—Ä–∏–∞–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
# # # #         except Exception as e:
# # # #             st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")


# # # # def run_app():
# # # #     st.set_page_config(page_title="StudyBuddy", layout="wide")
# # # #     st.title("üìò StudyBuddy: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫")

# # # #     handle_file_upload()

# # # #     history = get_session_history()
# # # #     tab1, tab2 = st.tabs(["üí¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", "üìù Quiz"])

# # # #     with tab1:
# # # #         st.subheader("–î–∏–∞–ª–æ–≥ —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º")
# # # #         question = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å:")
# # # #         use_pedagogy = st.checkbox("–†–µ–∂–∏–º –ø–æ–¥—Å–∫–∞–∑–æ–∫ (–Ω–µ –¥–∞–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ)", value=True)

# # # #         if st.button("–û—Ç–≤–µ—Ç–∏—Ç—å") and question:
# # # #             if use_pedagogy and should_hint(question):
# # # #                 answer = generate_hint(question)
# # # #             else:
# # # #                 answer = get_answer(question, st.session_state.chat_history)

# # # #             history.add_turn(question, answer)
# # # #             st.markdown(f"**–û—Ç–≤–µ—Ç:** {answer}")

# # # #             st.markdown("---")
# # # #             st.markdown("–û—Ü–µ–Ω–∏—Ç–µ –æ—Ç–≤–µ—Ç:")
# # # #             col1, col2 = st.columns(2)
# # # #             with col1:
# # # #                 if st.button("üëç –ü–æ–ª–µ–∑–Ω–æ"):
# # # #                     save_feedback(question, answer, True)
# # # #             with col2:
# # # #                 if st.button("üëé –ù–µ –ø–æ–ª–µ–∑–Ω–æ"):
# # # #                     save_feedback(question, answer, False)

# # # #         st.markdown("### –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:")
# # # #         for q, a in history.get_history():
# # # #             st.markdown(f"**–í—ã:** {q}\\n\\n**–ë–æ—Ç:** {a}")

# # # #     with tab2:
# # # #         st.subheader("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ")
# # # #         topic = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è —Ç–µ—Å—Ç–∞:")
# # # #         num_q = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤", 1, 10, 5)

# # # #         if st.button("–°–æ–∑–¥–∞—Ç—å Quiz"):
# # # #             quiz = generate_quiz(topic, num_q)
# # # #             st.text_area("–í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏", quiz, height=300)

# # # # if __name__ == "__main__":
# # # #     run_app()

# # # # import sys, os
# # # # sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
# # # # from config import embedding_model, OLLAMA_MODEL

# # # import sys, os
# # # from pathlib import Path
# # # sys.path.append(str(Path(__file__).parent.parent))
# # # from config import embedding_model, OLLAMA_MODEL

# # # # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞—ë–º –º–æ–¥–µ–ª—å Qwen
# # # import os as _os

# # # _os.environ.setdefault("OLLAMA_MODEL", "qwen2.5:1.5b-instruct")  # –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
# # # _os.environ.setdefault("OLLAMA_EMBED_MODEL", "nomic-embed-text") # –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
# # # _os.environ.setdefault("OLLAMA_BASE_URL", "http://localhost:11434")



# # # import streamlit as st
# # # from core.rag_engine import get_answer
# # # from core.pedagogy import should_hint, generate_hint
# # # from gui.session_manager import get_session_history
# # # from llm.quiz_generator import generate_quiz
# # # from ethics.user_feedback import save_feedback

# # # from data_ingestion.pdf_loader import extract_text_from_pdf
# # # from data_ingestion.docx_loader import extract_text_from_docx
# # # from data_ingestion.splitter import split_text
# # # from data_ingestion.preprocessor import clean_text
# # # from vector_db.faiss_interface import initialize_index

# # # UPLOAD_DIR = "uploaded_materials"




# # # import sys, os
# # # from pathlib import Path
# # # sys.path.append(str(Path(__file__).parent.parent))
# # # from config import OLLAMA_MODEL, embedding_model


# # # import streamlit as st
# # # from core.rag_engine import get_answer
# # # from core.pedagogy import should_hint, generate_hint
# # # from gui.session_manager import get_session_history
# # # from llm.quiz_generator import generate_quiz
# # # from ethics.user_feedback import save_feedback

# # # from data_ingestion.pdf_loader import extract_text_from_pdf
# # # from data_ingestion.docx_loader import extract_text_from_docx
# # # from data_ingestion.splitter import split_text
# # # from data_ingestion.preprocessor import clean_text
# # # from vector_db.faiss_interface import initialize_index

# # # UPLOAD_DIR = "uploaded_materials"

# # # def handle_file_upload():
# # #     st.subheader("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ–±–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞")
# # #     uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ PDF –∏–ª–∏ DOCX —Ñ–∞–π–ª", type=["pdf", "docx"])
# # #     if uploaded_file:
# # #         os.makedirs(UPLOAD_DIR, exist_ok=True)
# # #         file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
# # #         with open(file_path, "wb") as f:
# # #             f.write(uploaded_file.getbuffer())
# # #         st.success(f"–§–∞–π–ª '{uploaded_file.name}' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

# # #         try:
# # #             st.write("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞...")
# # #             if uploaded_file.name.endswith(".pdf"):
# # #                 raw_text = extract_text_from_pdf(file_path)
# # #             else:
# # #                 raw_text = extract_text_from_docx(file_path)

# # #             st.write(f"üìú –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(raw_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞.")

# # #             cleaned = clean_text(raw_text)
# # #             st.write(f"üßπ –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(cleaned)} —Å–∏–º–≤–æ–ª–æ–≤.")

# # #             chunks = split_text(cleaned)
# # #             st.write(f"üîπ –ß–∞–Ω–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(chunks)}")
# # #             if chunks:
# # #                 st.write(f"üß© –ü—Ä–∏–º–µ—Ä —á–∞–Ω–∫–∞:\n\n{chunks[0]}")

# # #             st.write("üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞...")
# # #             initialize_index(chunks)

# # #             st.session_state["documents"] = chunks
# # #             st.success("–ú–∞—Ç–µ—Ä–∏–∞–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
# # #         except Exception as e:
# # #             st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")

# # # def run_app():
# # #     st.set_page_config(page_title="StudyBuddy", layout="wide")
# # #     st.title("üìò StudyBuddy: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫")

# # #     handle_file_upload()

# # #     history = get_session_history()
# # #     tab1, tab2 = st.tabs(["üí¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", "üìù Quiz"])

# # #     with tab1:
# # #         st.subheader("–î–∏–∞–ª–æ–≥ —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º")
# # #         question = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å:")
# # #         use_pedagogy = st.checkbox("–†–µ–∂–∏–º –ø–æ–¥—Å–∫–∞–∑–æ–∫ (–Ω–µ –¥–∞–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ)", value=True)

# # #         if st.button("–û—Ç–≤–µ—Ç–∏—Ç—å") and question:
# # #             if "documents" not in st.session_state or not st.session_state["documents"]:
# # #                 st.warning("‚ùó –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–π—Ç–µ —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª.")
# # #             else:
# # #                 if use_pedagogy and should_hint(question):
# # #                     answer = generate_hint(question)
# # #                 else:
# # #                     answer = get_answer(question, st.session_state.chat_history)

# # #                 history.add_turn(question, answer)
# # #                 st.markdown(f"**–û—Ç–≤–µ—Ç:** {answer}")

# # #                 st.markdown("---")
# # #                 st.markdown("–û—Ü–µ–Ω–∏—Ç–µ –æ—Ç–≤–µ—Ç:")
# # #                 col1, col2 = st.columns(2)
# # #                 with col1:
# # #                     if st.button("üëç –ü–æ–ª–µ–∑–Ω–æ"):
# # #                         save_feedback(question, answer, True)
# # #                 with col2:
# # #                     if st.button("üëé –ù–µ –ø–æ–ª–µ–∑–Ω–æ"):
# # #                         save_feedback(question, answer, False)

# # #         st.markdown("### –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:")
# # #         for q, a in history.get_history():
# # #             st.markdown(f"**–í—ã:** {q}\n\n**–ë–æ—Ç:** {a}")

# # #     with tab2:
# # #         st.subheader("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ")
# # #         topic = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è —Ç–µ—Å—Ç–∞:")
# # #         num_q = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤", 1, 10, 5)

# # #         if st.button("–°–æ–∑–¥–∞—Ç—å Quiz"):
# # #             quiz = generate_quiz(topic, num_q)
# # #             st.text_area("–í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏", quiz, height=300)

# # # if __name__ == "__main__":
# # #     run_app()
# import sys, os
# from pathlib import Path
# sys.path.append(str(Path(__file__).parent.parent))
# from config import embedding_model, OLLAMA_MODEL
# from output.speech_output import speak

# # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞—ë–º –º–æ–¥–µ–ª—å Qwen
# import os as _os

# _os.environ.setdefault("OLLAMA_MODEL", "qwen2.5:1.5b-instruct")  # –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
# _os.environ.setdefault("OLLAMA_EMBED_MODEL", "nomic-embed-text") # –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
# _os.environ.setdefault("OLLAMA_BASE_URL", "http://localhost:11434")

# import streamlit as st
# from core.rag_engine import get_answer
# from core.pedagogy import should_hint, generate_hint
# from gui.session_manager import get_session_history
# from llm.quiz_generator import generate_quiz
# from ethics.user_feedback import save_feedback

# from data_ingestion.pdf_loader import extract_text_from_pdf
# from data_ingestion.docx_loader import extract_text_from_docx
# from data_ingestion.splitter import split_text
# from data_ingestion.preprocessor import clean_text


# UPLOAD_DIR = "uploaded_materials"




# import sys, os
# from pathlib import Path
# sys.path.append(str(Path(__file__).parent.parent))
# from config import OLLAMA_MODEL, embedding_model


# import streamlit as st
# from core.rag_engine import get_answer
# from core.pedagogy import should_hint, generate_hint
# from gui.session_manager import get_session_history
# from llm.quiz_generator import generate_quiz
# from ethics.user_feedback import save_feedback

# from data_ingestion.pdf_loader import extract_text_from_pdf
# from data_ingestion.docx_loader import extract_text_from_docx
# from data_ingestion.splitter import split_text
# from data_ingestion.preprocessor import clean_text
# from vector_db.faiss_interface import initialize_index

# UPLOAD_DIR = "uploaded_materials"

# def handle_file_upload():
#     st.subheader("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ–±–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞")
#     uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ PDF –∏–ª–∏ DOCX —Ñ–∞–π–ª", type=["pdf", "docx"])
#     if uploaded_file:
#         os.makedirs(UPLOAD_DIR, exist_ok=True)
#         file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
#         with open(file_path, "wb") as f:
#             f.write(uploaded_file.getbuffer())
#         st.success(f"–§–∞–π–ª '{uploaded_file.name}' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

#         try:
#             st.write("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞...")
#             if uploaded_file.name.endswith(".pdf"):
#                 raw_text = extract_text_from_pdf(file_path)
#             else:
#                 raw_text = extract_text_from_docx(file_path)

#             st.write(f"üìú –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(raw_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞.")

#             cleaned = clean_text(raw_text)
#             st.write(f"üßπ –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(cleaned)} —Å–∏–º–≤–æ–ª–æ–≤.")

#             chunks = split_text(cleaned)
#             st.write(f"üîπ –ß–∞–Ω–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(chunks)}")
#             if chunks:
#                 st.write(f"üß© –ü—Ä–∏–º–µ—Ä —á–∞–Ω–∫–∞:\n\n{chunks[0]}")

#             st.write("üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞...")
#             initialize_index(chunks)

#             st.session_state["documents"] = chunks
#             st.success("–ú–∞—Ç–µ—Ä–∏–∞–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
#         except Exception as e:
#             st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")

# def run_app():
#     st.set_page_config(page_title="StudyBuddy", layout="wide")
#     st.title("üìò StudyBuddy: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫")

#     handle_file_upload()

#     history = get_session_history()
#     tab1, tab2 = st.tabs(["üí¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", "üìù Quiz"])

#     with tab1:
#         st.subheader("–î–∏–∞–ª–æ–≥ —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º")
#         question = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å:")
#         use_pedagogy = st.checkbox("–†–µ–∂–∏–º –ø–æ–¥—Å–∫–∞–∑–æ–∫ (–Ω–µ –¥–∞–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ)", value=True)

#         if st.button("–û—Ç–≤–µ—Ç–∏—Ç—å") and question:
#             if "documents" not in st.session_state or not st.session_state["documents"]:
#                 st.warning("‚ùó –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–π—Ç–µ —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª.")
#             else:
#                 if use_pedagogy and should_hint(question):
#                     answer = generate_hint(question)
#                 else:
#                     answer = get_answer(question, st.session_state.chat_history)

#                 history.add_turn(question, answer)
#                 st.markdown(f"**–û—Ç–≤–µ—Ç:** {answer}")
#                 speak(answer)

#                 st.markdown("---")
#                 st.markdown("–û—Ü–µ–Ω–∏—Ç–µ –æ—Ç–≤–µ—Ç:")
#                 col1, col2 = st.columns(2)
#                 with col1:
#                     if st.button("üëç –ü–æ–ª–µ–∑–Ω–æ"):
#                         save_feedback(question, answer, True)
#                 with col2:
#                     if st.button("üëé –ù–µ –ø–æ–ª–µ–∑–Ω–æ"):
#                         save_feedback(question, answer, False)

#         st.markdown("### –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:")
#         for q, a in history.get_history():
#             st.markdown(f"**–í—ã:** {q}\n\n**–ë–æ—Ç:** {a}")

#     with tab2:
#         st.subheader("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ")
#         topic = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è —Ç–µ—Å—Ç–∞:")
#         num_q = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤", 1, 10, 5)

#         if st.button("–°–æ–∑–¥–∞—Ç—å Quiz"):
#             quiz = generate_quiz(topic, num_q)
#             st.text_area("–í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏", quiz, height=300)

# if __name__ == "__main__":
#     run_app()

import os
from pathlib import Path
import sys

# –ü—É—Ç–∏ –∏ –∫–æ–Ω—Ñ–∏–≥
sys.path.append(str(Path(__file__).parent.parent))
from config import embedding_model, OLLAMA_MODEL  # noqa: F401

# –§–∏–∫—Å–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ Ollama (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
os.environ.setdefault("OLLAMA_MODEL", "qwen2.5:1.5b-instruct")
os.environ.setdefault("OLLAMA_EMBED_MODEL", "nomic-embed-text")
os.environ.setdefault("OLLAMA_BASE_URL", "http://localhost:11434")

import streamlit as st
from core.rag_engine import get_answer
from core.pedagogy import should_hint, generate_hint
# from gui.session_manager import get_session_history  # –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω
from llm.quiz_generator import generate_quiz

from data_ingestion.pdf_loader import extract_text_from_pdf
from data_ingestion.docx_loader import extract_text_from_docx
from data_ingestion.splitter import split_text
from data_ingestion.preprocessor import clean_text
from vector_db.faiss_interface import initialize_index

UPLOAD_DIR = "uploaded_materials"

# ===================== In‚Äëmemory feedback/mastery ===================== #
def init_feedback_state():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è —Ñ–∏–¥–±–µ–∫–∞, –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞."""
    if "feedback" not in st.session_state:
        st.session_state.feedback = []    # [{q, a, understood, skills}]
    if "mastery" not in st.session_state:
        st.session_state.mastery = {}     # skill -> score
    if "last_answer_bundle" not in st.session_state:
        st.session_state.last_answer_bundle = None  # (q, a, skills)
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []  # —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (q, a)

def record_feedback(question: str, answer: str, understood: bool, skills=None):
    """–ö–æ–ª–ª–±—ç–∫ –¥–ª—è –∫–Ω–æ–ø–æ–∫ '–ü–æ–Ω—è—Ç–Ω–æ/–ù–µ –ø–æ–Ω—è—Ç–Ω–æ'."""
    item = {
        "q": question,
        "a": answer,
        "understood": understood,
        "skills": skills or []
    }
    st.session_state.feedback.append(item)
    for s in (item["skills"] or ["general"]):
        st.session_state.mastery[s] = st.session_state.mastery.get(s, 0) + (1 if understood else -1)
# ===================================================================== #

def handle_file_upload():
    st.subheader("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ–±–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞")
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ PDF –∏–ª–∏ DOCX —Ñ–∞–π–ª", type=["pdf", "docx"])
    if not uploaded_file:
        return

    os.makedirs(UPLOAD_DIR, exist_ok=True)
    file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    st.success(f"–§–∞–π–ª '{uploaded_file.name}' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

    try:
        st.write("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞...")
        if uploaded_file.name.endswith(".pdf"):
            raw_text = extract_text_from_pdf(file_path)
        else:
            raw_text = extract_text_from_docx(file_path)

        st.write(f"üìú –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(raw_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞.")
        cleaned = clean_text(raw_text)
        st.write(f"üßπ –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(cleaned)} —Å–∏–º–≤–æ–ª–æ–≤.")

        chunks = split_text(cleaned)
        st.write(f"üîπ –ß–∞–Ω–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(chunks)}")
        if chunks:
            st.write(f"üß© –ü—Ä–∏–º–µ—Ä —á–∞–Ω–∫–∞:\n\n{chunks[0]}")

        st.write("üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞...")
        initialize_index(chunks)

        st.session_state["documents"] = chunks
        st.success("–ú–∞—Ç–µ—Ä–∏–∞–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")

# --- –ú—è–≥–∫–∞—è –ø–æ–¥–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è TTS (–Ω–µ –º–µ–Ω—è–µ—Ç —Å–∞–º –æ—Ç–≤–µ—Ç –Ω–∞ —ç–∫—Ä–∞–Ω–µ)
def sanitize_for_tts(text: str) -> str:
    low = text.lower()
    if "–±–∏—Ç —Ä–∞–≤–µ–Ω 1 –±–∞–π—Ç—É" in low or "–±–∏—Ç = 1 –±–∞–π—Ç" in low:
        text += "\n–£—Ç–æ—á–Ω–µ–Ω–∏–µ: –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ 1 –±–∞–π—Ç = 8 –±–∏—Ç."
    return text

def run_app():
    st.set_page_config(page_title="StudyBuddy", layout="wide")
    st.title("üìò StudyBuddy: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è in‚Äëmemory —Å–æ—Å—Ç–æ—è–Ω–∏—è
    init_feedback_state()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
    handle_file_upload()

    tab1, tab2, tab3 = st.tabs(["üí¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", "üìù Quiz", "üìà –ü—Ä–æ–≥—Ä–µ—Å—Å"])

    with tab1:
        st.subheader("–î–∏–∞–ª–æ–≥ —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º")
        question = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å:")
        use_pedagogy = st.checkbox("–†–µ–∂–∏–º –ø–æ–¥—Å–∫–∞–∑–æ–∫ (–Ω–µ –¥–∞–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ)", value=True)

        if st.button("–û—Ç–≤–µ—Ç–∏—Ç—å") and question:
            if "documents" not in st.session_state or not st.session_state["documents"]:
                st.warning("‚ùó –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–π—Ç–µ —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª.")
            else:
                if use_pedagogy and should_hint(question):
                    answer = generate_hint(question)
                    skills = None   # –º–æ–∂–Ω–æ –ø–æ–∑–∂–µ –ø–æ–¥—Å—Ç–∞–≤–ª—è—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–µ–º
                else:
                    answer = get_answer(question, st.session_state.chat_history)
                    skills = None   # TODO: –ø—Ä–æ–∫–∏–Ω—É—Ç—å —Ç–µ–º—ã –∏–∑ retrieve, –µ—Å–ª–∏ –µ—Å—Ç—å

                # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
                st.session_state.chat_history.append((question, answer))
                st.session_state.last_answer_bundle = (question, answer, skills)

                st.markdown(f"**–û—Ç–≤–µ—Ç:** {answer}")
                # –ê–∫–∫—É—Ä–∞—Ç–Ω–∞—è –æ–∑–≤—É—á–∫–∞
                try:
                    from output.speech_output import speak
                    safe_answer = sanitize_for_tts(answer)
                    speak(safe_answer, flush=False, debounce_sec=1.0)
                except Exception as e:
                    st.warning(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {e}")

                st.markdown("---")
                st.markdown("–û—Ü–µ–Ω–∏—Ç–µ –ø–æ–Ω—è—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞:")

                col1, col2 = st.columns(2)
                # –¥–µ–ª–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è –∫–Ω–æ–ø–æ–∫ –Ω–∞ –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç
                uid = f"{len(st.session_state.feedback)}_{abs(hash(question)) % 10_000_000}"

                q_cur, a_cur, skills_cur = st.session_state.last_answer_bundle

                col1.button(
                    "üëç –ü–æ–Ω—è—Ç–Ω–æ",
                    key=f"fb_ok_{uid}",
                    on_click=record_feedback,
                    args=(q_cur, a_cur, True, skills_cur)
                )
                col2.button(
                    "ü§î –ù–µ –ø–æ–Ω—è—Ç–Ω–æ",
                    key=f"fb_bad_{uid}",
                    on_click=record_feedback,
                    args=(q_cur, a_cur, False, skills_cur)
                )

        # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ (—á–∏—Å—Ç–æ –∏–∑ session_state)
        st.markdown("### –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:")
        for q, a in st.session_state.chat_history:
            st.markdown(f"**–í—ã:** {q}\n\n**–ë–æ—Ç:** {a}")

    with tab2:
        st.subheader("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ")
        topic = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è —Ç–µ—Å—Ç–∞:")
        num_q = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤", 1, 10, 5)

        if st.button("–°–æ–∑–¥–∞—Ç—å Quiz"):
            quiz = generate_quiz(topic, num_q)
            st.text_area("–í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏", quiz, height=300)

    with tab3:
        st.subheader("–í–∞—à –ø—Ä–æ–≥—Ä–µ—Å—Å –∑–∞ —Ç–µ–∫—É—â—É—é —Å–µ—Å—Å–∏—é")

        # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –ø–æ '–º–∞—Å—Ç–µ—Ä—Å—Ç–≤—É'
        if st.session_state.mastery:
            st.write("**–°—É–º–º–∞—Ä–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ —Ç–µ–º–∞–º** (—É—Å–ª–æ–≤–Ω—ã–µ –±–∞–ª–ª—ã):")
            try:
                import pandas as pd
                df = pd.DataFrame(
                    {"skill": list(st.session_state.mastery.keys()),
                     "score": list(st.session_state.mastery.values())}
                ).set_index("skill")
                st.bar_chart(df)
            except Exception:
                st.json(st.session_state.mastery)
        else:
            st.info("–ü–æ–∫–∞ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö. –û—Ü–µ–Ω–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –æ—Ç–≤–µ—Ç –∫–Ω–æ–ø–∫–∞–º–∏ –≤—ã—à–µ.")

        st.markdown("---")
        st.write("**–û—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤:**")
        if st.session_state.feedback:
            try:
                import pandas as pd
                fb_rows = [{
                    "–í–æ–ø—Ä–æ—Å": it["q"],
                    "–ü–æ–Ω—è—Ç–Ω–æ": "–î–∞" if it["understood"] else "–ù–µ—Ç",
                    "–¢–µ–º—ã": ", ".join(it["skills"]) if it["skills"] else "‚Äî"
                } for it in st.session_state.feedback]
                st.dataframe(pd.DataFrame(fb_rows))
            except Exception:
                for it in st.session_state.feedback:
                    st.write(f"- –ü–æ–Ω—è—Ç–Ω–æ: {'–î–∞' if it['understood'] else '–ù–µ—Ç'} | –¢–µ–º—ã: {', '.join(it['skills']) if it['skills'] else '‚Äî'}")
                    st.caption(f"–í–æ–ø—Ä–æ—Å: {it['q']}")
        else:
            st.write("–ï—â—ë –Ω–µ—Ç –æ—Ü–µ–Ω–æ–∫ –∑–∞ —ç—Ç—É —Å–µ—Å—Å–∏—é.")

if __name__ == "__main__":
    run_app()
